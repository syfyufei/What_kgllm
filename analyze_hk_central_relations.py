#!/usr/bin/env python3
"""åˆ†æé¦™æ¸¯ä¸ä¸­å¤®æ”¿åºœå…³ç³»çš„ä¸“é—¨è„šæœ¬"""

import json
from collections import Counter, defaultdict
import re

def load_kg_data(file_path):
    """åŠ è½½çŸ¥è¯†å›¾è°±æ•°æ®"""
    print(f"ğŸ“‚ åŠ è½½çŸ¥è¯†å›¾è°±æ•°æ®è¿›è¡Œé¦™æ¸¯-ä¸­å¤®å…³ç³»åˆ†æ...")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"âœ… æˆåŠŸåŠ è½½ {len(data)} ä¸ªä¸‰å…ƒç»„")
    return data

def extract_hk_central_relations(data):
    """æå–é¦™æ¸¯ä¸ä¸­å¤®ç›¸å…³çš„å…³ç³»"""
    print("\n" + "="*60)
    print("ğŸ›ï¸ é¦™æ¸¯ä¸ä¸­å¤®æ”¿åºœå…³ç³»åˆ†æ")
    print("="*60)
    
    # å®šä¹‰é¦™æ¸¯ç›¸å…³å…³é”®è¯
    hk_keywords = [
        'é¦™æ¸¯', 'ç‰¹åŒº', 'ç‰¹åˆ«è¡Œæ”¿åŒº', 'æ¸¯åºœ', 'é¦™æ¸¯æ”¿åºœ', 
        'è¡Œæ”¿é•¿å®˜', 'ç«‹æ³•ä¼š', 'å¸æ³•æœºå…³', 'åŸºæœ¬æ³•'
    ]
    
    # å®šä¹‰ä¸­å¤®ç›¸å…³å…³é”®è¯
    central_keywords = [
        'ä¸­å¤®', 'ä¸­å¤®æ”¿åºœ', 'å›½å®¶', 'å…¨å›½', 'å†…åœ°', 
        'ä¸­å…±ä¸­å¤®', 'å›½åŠ¡é™¢', 'äººå¤§', 'ä¸­åäººæ°‘å…±å’Œå›½'
    ]
    
    # å®šä¹‰ä¸€å›½ä¸¤åˆ¶ç›¸å…³å…³é”®è¯
    octs_keywords = [
        'ä¸€å›½ä¸¤åˆ¶', 'æ¸¯äººæ²»æ¸¯', 'é«˜åº¦è‡ªæ²»', 'çˆ±å›½è€…æ²»æ¸¯',
        'åŸºæœ¬æ³•', 'å®ªæ³•', 'å›½å®¶å®‰å…¨', 'äºŒåä¸‰æ¡'
    ]
    
    # æå–ç›¸å…³ä¸‰å…ƒç»„
    hk_central_triples = []
    hk_triples = []
    central_triples = []
    octs_triples = []
    
    for item in data:
        text = f"{item['subject']} {item['predicate']} {item['object']}"
        
        # é¦™æ¸¯-ä¸­å¤®ç›´æ¥å…³ç³»
        has_hk = any(keyword in text for keyword in hk_keywords)
        has_central = any(keyword in text for keyword in central_keywords)
        has_octs = any(keyword in text for keyword in octs_keywords)
        
        if has_hk and has_central:
            hk_central_triples.append(item)
        elif has_hk:
            hk_triples.append(item)
        elif has_central:
            central_triples.append(item)
        
        if has_octs:
            octs_triples.append(item)
    
    print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"   â€¢ é¦™æ¸¯-ä¸­å¤®ç›´æ¥å…³ç³»: {len(hk_central_triples)} ä¸ªä¸‰å…ƒç»„")
    print(f"   â€¢ é¦™æ¸¯ç›¸å…³å…³ç³»: {len(hk_triples)} ä¸ªä¸‰å…ƒç»„")
    print(f"   â€¢ ä¸­å¤®ç›¸å…³å…³ç³»: {len(central_triples)} ä¸ªä¸‰å…ƒç»„")
    print(f"   â€¢ ä¸€å›½ä¸¤åˆ¶ç›¸å…³å…³ç³»: {len(octs_triples)} ä¸ªä¸‰å…ƒç»„")
    
    return hk_central_triples, hk_triples, central_triples, octs_triples

def analyze_direct_relations(hk_central_triples):
    """åˆ†æé¦™æ¸¯ä¸ä¸­å¤®çš„ç›´æ¥å…³ç³»"""
    print("\n" + "="*50)
    print("ğŸ¤ é¦™æ¸¯-ä¸­å¤®ç›´æ¥å…³ç³»åˆ†æ")
    print("="*50)
    
    if not hk_central_triples:
        print("âŒ æœªæ‰¾åˆ°é¦™æ¸¯ä¸ä¸­å¤®çš„ç›´æ¥å…³ç³»")
        return
    
    print(f"ğŸ“ˆ å‘ç° {len(hk_central_triples)} ä¸ªç›´æ¥å…³ç³»:")
    
    # åˆ†æå…³ç³»ç±»å‹
    relations = [item['predicate'] for item in hk_central_triples]
    relation_counts = Counter(relations)
    
    print("\nğŸ”— å…³ç³»ç±»å‹åˆ†å¸ƒ:")
    for i, (relation, count) in enumerate(relation_counts.most_common(10), 1):
        percentage = (count / len(hk_central_triples)) * 100
        print(f"{i:2d}. {relation:<20} {count:>3} æ¬¡ ({percentage:4.1f}%)")
    
    # æ˜¾ç¤ºå…·ä½“å…³ç³»
    print(f"\nğŸ“‹ å…·ä½“å…³ç³»ç¤ºä¾‹ï¼ˆå‰20ä¸ªï¼‰:")
    for i, item in enumerate(hk_central_triples[:20], 1):
        print(f"{i:2d}. {item['subject']} â†’ {item['predicate']} â†’ {item['object']}")
    
    return relation_counts

def analyze_support_relations(data):
    """åˆ†æä¸­å¤®å¯¹é¦™æ¸¯çš„æ”¯æŒå…³ç³»"""
    print("\n" + "="*50)
    print("ğŸ¯ ä¸­å¤®å¯¹é¦™æ¸¯æ”¯æŒå…³ç³»åˆ†æ")
    print("="*50)
    
    support_keywords = ['æ”¯æŒ', 'æ”¯æ´', 'ååŠ©', 'å¸®åŠ©', 'ä¿ƒè¿›', 'æ¨åŠ¨', 'é¼“åŠ±']
    central_keywords = ['ä¸­å¤®', 'ä¸­å¤®æ”¿åºœ', 'å›½å®¶', 'å†…åœ°']
    hk_keywords = ['é¦™æ¸¯', 'ç‰¹åŒº', 'ç‰¹åˆ«è¡Œæ”¿åŒº']
    
    support_relations = []
    
    for item in data:
        # ä¸­å¤®æ”¯æŒé¦™æ¸¯
        if (any(ck in item['subject'] for ck in central_keywords) and 
            any(sk in item['predicate'] for sk in support_keywords) and
            any(hk in item['object'] for hk in hk_keywords)):
            support_relations.append(item)
        
        # æˆ–è€…é¦™æ¸¯è·å¾—ä¸­å¤®æ”¯æŒ
        elif (any(hk in item['subject'] for hk in hk_keywords) and
              any(ck in item['object'] for ck in central_keywords) and
              any(sk in item['predicate'] for sk in support_keywords)):
            support_relations.append(item)
    
    print(f"ğŸ“Š å‘ç° {len(support_relations)} ä¸ªæ”¯æŒå…³ç³»:")
    
    if support_relations:
        for i, item in enumerate(support_relations[:15], 1):
            print(f"{i:2d}. {item['subject']} â†’ {item['predicate']} â†’ {item['object']}")
    
    return support_relations

def analyze_octs_implementation(octs_triples):
    """åˆ†æä¸€å›½ä¸¤åˆ¶å®æ–½æƒ…å†µ"""
    print("\n" + "="*50)
    print("ğŸ›ï¸ ä¸€å›½ä¸¤åˆ¶å®æ–½åˆ†æ")
    print("="*50)
    
    if not octs_triples:
        print("âŒ æœªæ‰¾åˆ°ä¸€å›½ä¸¤åˆ¶ç›¸å…³å…³ç³»")
        return
    
    print(f"ğŸ“Š ä¸€å›½ä¸¤åˆ¶ç›¸å…³å…³ç³»: {len(octs_triples)} ä¸ª")
    
    # åˆ†æå…³é”®æ¦‚å¿µ
    key_concepts = defaultdict(int)
    
    for item in octs_triples:
        text = f"{item['subject']} {item['object']}"
        
        concepts = {
            'åŸºæœ¬æ³•': ['åŸºæœ¬æ³•', 'å®ªæ³•'],
            'é«˜åº¦è‡ªæ²»': ['é«˜åº¦è‡ªæ²»', 'è‡ªæ²»æƒ'],
            'æ¸¯äººæ²»æ¸¯': ['æ¸¯äººæ²»æ¸¯', 'é¦™æ¸¯äºº'],
            'çˆ±å›½è€…æ²»æ¸¯': ['çˆ±å›½è€…æ²»æ¸¯', 'çˆ±å›½'],
            'å›½å®¶å®‰å…¨': ['å›½å®¶å®‰å…¨', 'å®‰å…¨', 'ç¨³å®š'],
            'å¸æ³•ç‹¬ç«‹': ['å¸æ³•', 'æ³•é™¢', 'æ³•å®˜'],
            'è¡Œæ”¿ä¸»å¯¼': ['è¡Œæ”¿é•¿å®˜', 'æ”¿åºœ', 'è¡Œæ”¿']
        }
        
        for concept, keywords in concepts.items():
            if any(keyword in text for keyword in keywords):
                key_concepts[concept] += 1
    
    print("\nğŸ“ˆ ä¸€å›½ä¸¤åˆ¶æ ¸å¿ƒæ¦‚å¿µåˆ†å¸ƒ:")
    for concept, count in sorted(key_concepts.items(), key=lambda x: x[1], reverse=True):
        print(f"   â€¢ {concept:<12} {count:>3} æ¬¡")
    
    # æ˜¾ç¤ºå…·ä½“å…³ç³»
    print(f"\nğŸ“‹ ä¸€å›½ä¸¤åˆ¶å…·ä½“å®æ–½ï¼ˆå‰15ä¸ªï¼‰:")
    for i, item in enumerate(octs_triples[:15], 1):
        print(f"{i:2d}. {item['subject']} â†’ {item['predicate']} â†’ {item['object']}")
    
    return key_concepts

def analyze_cooperation_areas(data):
    """åˆ†æåˆä½œé¢†åŸŸ"""
    print("\n" + "="*50)
    print("ğŸ¤ æ¸¯ä¸­åˆä½œé¢†åŸŸåˆ†æ")
    print("="*50)
    
    cooperation_areas = {
        'ç»æµåˆä½œ': ['ç»æµ', 'è´¸æ˜“', 'æŠ•èµ„', 'é‡‘è', 'å¸‚åœº', 'å•†ä¸š'],
        'ç§‘æŠ€åˆä½œ': ['ç§‘æŠ€', 'åˆ›æ–°', 'æŠ€æœ¯', 'ç ”å‘', 'æ•°å­—', 'æ™ºèƒ½'],
        'æ•™è‚²åˆä½œ': ['æ•™è‚²', 'å­¦æ ¡', 'å¤§å­¦', 'å­¦ç”Ÿ', 'äººæ‰', 'åŸ¹è®­'],
        'æ–‡åŒ–åˆä½œ': ['æ–‡åŒ–', 'è‰ºæœ¯', 'ä½“è‚²', 'æ—…æ¸¸', 'äº¤æµ', 'ä¼ ç»Ÿ'],
        'åŸºå»ºåˆä½œ': ['åŸºç¡€è®¾æ–½', 'äº¤é€š', 'å»ºè®¾', 'å·¥ç¨‹', 'æ¸¯å£', 'æœºåœº'],
        'åŒ»ç–—åˆä½œ': ['åŒ»ç–—', 'å¥åº·', 'åŒ»é™¢', 'è¯ç‰©', 'æ²»ç–—', 'å«ç”Ÿ'],
        'ç¯ä¿åˆä½œ': ['ç¯å¢ƒ', 'ç¯ä¿', 'ç»¿è‰²', 'å¯æŒç»­', 'æ°”å€™', 'ç”Ÿæ€']
    }
    
    area_relations = defaultdict(list)
    
    for item in data:
        text = f"{item['subject']} {item['predicate']} {item['object']}"
        
        # æ£€æŸ¥æ˜¯å¦æ¶‰åŠé¦™æ¸¯å’Œå†…åœ°/ä¸­å¤®
        has_hk = any(keyword in text for keyword in ['é¦™æ¸¯', 'ç‰¹åŒº'])
        has_mainland = any(keyword in text for keyword in ['å†…åœ°', 'ä¸­å¤®', 'å›½å®¶'])
        
        if has_hk and has_mainland:
            for area, keywords in cooperation_areas.items():
                if any(keyword in text for keyword in keywords):
                    area_relations[area].append(item)
    
    print("ğŸ“Š åˆä½œé¢†åŸŸåˆ†å¸ƒ:")
    for area, relations in sorted(area_relations.items(), key=lambda x: len(x[1]), reverse=True):
        print(f"   â€¢ {area:<12} {len(relations):>3} ä¸ªå…³ç³»")
    
    # æ˜¾ç¤ºæ¯ä¸ªé¢†åŸŸçš„å…·ä½“åˆä½œ
    for area, relations in area_relations.items():
        if relations:
            print(f"\nğŸ”¹ {area}åˆä½œç¤ºä¾‹:")
            for i, item in enumerate(relations[:5], 1):
                print(f"   {i}. {item['subject']} â†’ {item['predicate']} â†’ {item['object']}")
    
    return area_relations

def analyze_policy_coordination(data):
    """åˆ†ææ”¿ç­–åè°ƒæœºåˆ¶"""
    print("\n" + "="*50)
    print("âš™ï¸ æ”¿ç­–åè°ƒæœºåˆ¶åˆ†æ")
    print("="*50)
    
    coordination_keywords = [
        'åè°ƒ', 'ç»Ÿç­¹', 'é…åˆ', 'è¡”æ¥', 'å¯¹æ¥', 
        'æ²Ÿé€š', 'è”ç³»', 'åˆä½œ', 'åä½œ', 'è”åŠ¨'
    ]
    
    coordination_relations = []
    
    for item in data:
        text = f"{item['subject']} {item['predicate']} {item['object']}"
        
        # æ¶‰åŠé¦™æ¸¯å’Œä¸­å¤®çš„åè°ƒ
        has_hk = any(keyword in text for keyword in ['é¦™æ¸¯', 'ç‰¹åŒº'])
        has_central = any(keyword in text for keyword in ['ä¸­å¤®', 'å†…åœ°', 'å›½å®¶'])
        has_coordination = any(keyword in item['predicate'] for keyword in coordination_keywords)
        
        if (has_hk and has_central and has_coordination):
            coordination_relations.append(item)
    
    print(f"ğŸ“Š å‘ç° {len(coordination_relations)} ä¸ªåè°ƒæœºåˆ¶:")
    
    if coordination_relations:
        for i, item in enumerate(coordination_relations[:10], 1):
            print(f"{i:2d}. {item['subject']} â†’ {item['predicate']} â†’ {item['object']}")
    
    return coordination_relations

def generate_hk_central_summary(hk_central_triples, support_relations, octs_triples, cooperation_areas):
    """ç”Ÿæˆé¦™æ¸¯-ä¸­å¤®å…³ç³»æ€»ç»“"""
    print("\n" + "="*60)
    print("ğŸ“‹ é¦™æ¸¯ä¸ä¸­å¤®æ”¿åºœå…³ç³»æ€»ç»“æŠ¥å‘Š")
    print("="*60)
    
    total_relations = len(hk_central_triples) + len(support_relations) + len(octs_triples)
    
    print(f"""
ğŸ¯ å…³ç³»æ¦‚è§ˆ:
   â€¢ ç›´æ¥å…³ç³»: {len(hk_central_triples)} ä¸ª
   â€¢ æ”¯æŒå…³ç³»: {len(support_relations)} ä¸ª  
   â€¢ ä¸€å›½ä¸¤åˆ¶å…³ç³»: {len(octs_triples)} ä¸ª
   â€¢ åˆä½œé¢†åŸŸ: {len(cooperation_areas)} ä¸ª

ğŸ›ï¸ åˆ¶åº¦æ¡†æ¶:
   â€¢ ä¸€å›½ä¸¤åˆ¶æ˜¯æ ¹æœ¬åˆ¶åº¦å®‰æ’
   â€¢ åŸºæœ¬æ³•æ˜¯å®ªåˆ¶åŸºç¡€
   â€¢ é«˜åº¦è‡ªæ²»ä¸ä¸­å¤®å…¨é¢ç®¡æ²»æƒç›¸ç»“åˆ
   â€¢ çˆ±å›½è€…æ²»æ¸¯åŸåˆ™å¾—åˆ°è½å®

ğŸ¤ åˆä½œç‰¹ç‚¹:
   â€¢ ç»æµåˆä½œæ˜¯é‡ç‚¹é¢†åŸŸ
   â€¢ ç§‘æŠ€åˆ›æ–°åˆä½œæ—¥ç›Šé‡è¦
   â€¢ æ•™è‚²æ–‡åŒ–äº¤æµæŒç»­æ·±åŒ–
   â€¢ åŸºç¡€è®¾æ–½äº’è”äº’é€šåŠ å¼º

ğŸ’¡ å…³ç³»ç‰¹å¾:
   â€¢ ä¸­å¤®å¯¹é¦™æ¸¯ç»™äºˆå¼ºæœ‰åŠ›æ”¯æŒ
   â€¢ é¦™æ¸¯ç§¯æèå…¥å›½å®¶å‘å±•å¤§å±€
   â€¢ æ”¿ç­–åè°ƒæœºåˆ¶ä¸æ–­å®Œå–„
   â€¢ åˆä½œé¢†åŸŸå…¨é¢æ‹“å±•

ğŸ”® å‘å±•è¶‹åŠ¿:
   â€¢ åˆ¶åº¦ä¼˜åŠ¿è¿›ä¸€æ­¥å‘æŒ¥
   â€¢ åˆä½œå±‚æ¬¡ä¸æ–­æå‡
   â€¢ åè°ƒæœºåˆ¶æ—¥è¶‹å®Œå–„
   â€¢ å…±åŒå‘å±•å‰æ™¯å¹¿é˜”
    """)

def main():
    """ä¸»å‡½æ•°"""
    file_path = "/Users/adrian/Documents/GitHub/What_kgllm/complete_policy_address_kg.json"
    
    try:
        # åŠ è½½æ•°æ®
        data = load_kg_data(file_path)
        
        # æå–ç›¸å…³å…³ç³»
        hk_central_triples, hk_triples, central_triples, octs_triples = extract_hk_central_relations(data)
        
        # å„é¡¹åˆ†æ
        relation_counts = analyze_direct_relations(hk_central_triples)
        support_relations = analyze_support_relations(data)
        key_concepts = analyze_octs_implementation(octs_triples)
        cooperation_areas = analyze_cooperation_areas(data)
        coordination_relations = analyze_policy_coordination(data)
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        generate_hk_central_summary(hk_central_triples, support_relations, octs_triples, cooperation_areas)
        
        print(f"\nâœ… é¦™æ¸¯ä¸ä¸­å¤®æ”¿åºœå…³ç³»åˆ†æå®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()