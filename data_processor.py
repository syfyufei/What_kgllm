#!/usr/bin/env python3
"""
é¦™æ¸¯æ–½æ”¿æŠ¥å‘Šæ•°æ®å¤„ç†å™¨
åŠŸèƒ½ï¼š
1. æå–PDFå’ŒXMLæ ¼å¼çš„æ–½æ”¿æŠ¥å‘Šæ–‡æœ¬
2. ç»Ÿä¸€æ ¼å¼å¹¶è½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡
3. ç”Ÿæˆæ ‡å‡†åŒ–çš„æ–‡æœ¬æ–‡ä»¶ä¾›çŸ¥è¯†å›¾è°±åˆ†æä½¿ç”¨
"""

import os
import re
import json
import xml.etree.ElementTree as ET
from pathlib import Path
from typing import Dict, List, Optional
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥æ‰€éœ€çš„åº“
try:
    import PyPDF2
    import pdfplumber
    HAS_PDF_LIBS = True
except ImportError:
    print("âš ï¸  PDFå¤„ç†åº“æœªå®‰è£…ï¼Œå°†è·³è¿‡PDFæ–‡ä»¶å¤„ç†")
    print("   å®‰è£…å‘½ä»¤: pip install PyPDF2 pdfplumber")
    HAS_PDF_LIBS = False

try:
    from opencc import OpenCC
    HAS_OPENCC = True
except ImportError:
    print("âš ï¸  OpenCCæœªå®‰è£…ï¼Œå°†è·³è¿‡ç¹ç®€è½¬æ¢")
    print("   å®‰è£…å‘½ä»¤: pip install opencc-python-reimplemented")
    HAS_OPENCC = False

class PolicyAddressProcessor:
    """æ–½æ”¿æŠ¥å‘Šå¤„ç†å™¨"""

    def __init__(self, source_dir="data/pa", output_dir="policy_data/raw_texts"):
        self.source_dir = Path(source_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # åˆå§‹åŒ–ç¹ç®€è½¬æ¢å™¨
        if HAS_OPENCC:
            self.converter = OpenCC('t2s')  # ç¹ä½“è½¬ç®€ä½“
        else:
            self.converter = None

        # å­˜å‚¨å¤„ç†ç»“æœ
        self.processing_log = []

    def convert_to_simplified(self, text: str) -> str:
        """å°†ç¹ä½“ä¸­æ–‡è½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡"""
        if self.converter and text:
            try:
                return self.converter.convert(text)
            except Exception as e:
                print(f"âš ï¸  ç¹ç®€è½¬æ¢å¤±è´¥: {str(e)}")
                return text
        return text

    def clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬å†…å®¹"""
        if not text:
            return ""

        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        text = re.sub(r'\s+', ' ', text)

        # ç§»é™¤é¡µç å’Œé¡µçœ‰é¡µè„šæ¨¡å¼
        text = re.sub(r'ç¬¬\s*\d+\s*é¡µ', '', text)
        text = re.sub(r'Page\s*\d+', '', text, flags=re.IGNORECASE)

        # ç§»é™¤é‡å¤çš„åˆ†éš”ç¬¦
        text = re.sub(r'-{3,}', '---', text)
        text = re.sub(r'={3,}', '===', text)

        # ç§»é™¤å¤šä½™çš„æ¢è¡Œç¬¦
        text = re.sub(r'\n{3,}', '\n\n', text)

        # æ¸…ç†é¦–å°¾ç©ºç™½
        text = text.strip()

        return text

    def extract_from_xml(self, file_path: Path) -> str:
        """ä»XMLæ–‡ä»¶æå–æ–‡æœ¬"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # å¤„ç†XMLæ ¼å¼
            if content.startswith('<?xml'):
                # æ ‡å‡†XMLæ ¼å¼
                try:
                    root = ET.fromstring(content)
                    # æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹
                    text_parts = []
                    for elem in root.iter():
                        if elem.text and elem.text.strip():
                            text_parts.append(elem.text.strip())
                        if elem.tail and elem.tail.strip():
                            text_parts.append(elem.tail.strip())

                    text = '\n'.join(text_parts)
                except ET.ParseError:
                    # å¦‚æœXMLè§£æå¤±è´¥ï¼Œç›´æ¥æå–æ–‡æœ¬
                    text = re.sub(r'<[^>]+>', '', content)
            else:
                # çº¯æ–‡æœ¬æ ¼å¼
                text = content

            return self.clean_text(text)

        except Exception as e:
            print(f"âŒ XMLæå–å¤±è´¥ {file_path}: {str(e)}")
            return ""

    def extract_from_pdf(self, file_path: Path) -> str:
        """ä»PDFæ–‡ä»¶æå–æ–‡æœ¬"""
        if not HAS_PDF_LIBS:
            print(f"âš ï¸  è·³è¿‡PDFæ–‡ä»¶ {file_path.name}ï¼ˆç¼ºå°‘PDFå¤„ç†åº“ï¼‰")
            return ""

        text = ""

        # å°è¯•ä½¿ç”¨pdfplumberæå–
        try:
            import pdfplumber
            with pdfplumber.open(file_path) as pdf:
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"

            if text.strip():
                return self.clean_text(text)
        except Exception as e:
            print(f"âš ï¸  pdfplumberæå–å¤±è´¥: {str(e)}")

        # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨PyPDF2
        try:
            import PyPDF2
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                for page in pdf_reader.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"

            return self.clean_text(text)

        except Exception as e:
            print(f"âŒ PDFæå–å¤±è´¥ {file_path}: {str(e)}")
            return ""

    def extract_year_from_filename(self, filename: str) -> Optional[int]:
        """ä»æ–‡ä»¶åæå–å¹´ä»½"""
        # åŒ¹é…å¹´ä»½æ¨¡å¼
        patterns = [
            r'pa(\d{4})\.(?:xml|pdf)',  # pa1997.xml, pa2024.pdf
            r'PA(\d{4})\.pdf',          # PA2013.pdf
            r'pa(\d{4})(\d{2})\.pdf'    # pa200502.pdf (ç‰¹æ®Šæƒ…å†µ)
        ]

        for pattern in patterns:
            match = re.search(pattern, filename, re.IGNORECASE)
            if match:
                year = int(match.group(1))
                # å¤„ç†ç‰¹æ®Šæƒ…å†µ pa200502.pdf
                if len(match.groups()) > 1 and match.group(2):
                    # è¿™æ˜¯2005å¹´çš„ç¬¬äºŒä»½æŠ¥å‘Šï¼Œæˆ‘ä»¬æ ‡è®°ä¸º2005
                    pass
                return year

        return None

    def process_single_file(self, file_path: Path) -> bool:
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        print(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {file_path.name}")

        # æå–å¹´ä»½
        year = self.extract_year_from_filename(file_path.name)
        if not year:
            print(f"âŒ æ— æ³•ä»æ–‡ä»¶åæå–å¹´ä»½: {file_path.name}")
            return False

        # æå–æ–‡æœ¬å†…å®¹
        if file_path.suffix.lower() == '.xml':
            text = self.extract_from_xml(file_path)
        elif file_path.suffix.lower() == '.pdf':
            text = self.extract_from_pdf(file_path)
        else:
            print(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path.name}")
            return False

        if not text or len(text.strip()) < 100:
            print(f"âŒ æå–çš„æ–‡æœ¬å†…å®¹è¿‡å°‘: {file_path.name}")
            return False

        # è½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡
        simplified_text = self.convert_to_simplified(text)

        # æ·»åŠ æ ‡é¢˜å’Œå…ƒä¿¡æ¯
        header = f"é¦™æ¸¯ç‰¹åˆ«è¡Œæ”¿åŒºè¡Œæ”¿é•¿å®˜{year}å¹´æ–½æ”¿æŠ¥å‘Š\n\n"
        final_text = header + simplified_text

        # ä¿å­˜åˆ°è¾“å‡ºæ–‡ä»¶
        output_file = self.output_dir / f"policy_address_{year}.txt"
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(final_text)

            # è®°å½•å¤„ç†ç»“æœ
            result = {
                'year': year,
                'source_file': str(file_path),
                'output_file': str(output_file),
                'text_length': len(final_text),
                'status': 'success'
            }
            self.processing_log.append(result)

            print(f"âœ… {year}å¹´æ–½æ”¿æŠ¥å‘Šå¤„ç†å®Œæˆ ({len(final_text):,} å­—ç¬¦)")
            return True

        except Exception as e:
            print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥ {output_file}: {str(e)}")
            return False

    def process_all_files(self):
        """å¤„ç†æ‰€æœ‰æ–‡ä»¶"""
        print("ğŸš€ å¼€å§‹å¤„ç†é¦™æ¸¯æ–½æ”¿æŠ¥å‘Šæ•°æ®")
        print("="*60)

        if not self.source_dir.exists():
            print(f"âŒ æºæ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.source_dir}")
            return

        # è·å–æ‰€æœ‰æ–‡ä»¶
        files = list(self.source_dir.glob("*.xml")) + list(self.source_dir.glob("*.pdf"))
        files.sort()

        if not files:
            print(f"âŒ åœ¨ {self.source_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½•XMLæˆ–PDFæ–‡ä»¶")
            return

        print(f"ğŸ“ æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶")

        # å¤„ç†æ¯ä¸ªæ–‡ä»¶
        success_count = 0
        for file_path in files:
            if self.process_single_file(file_path):
                success_count += 1
            print()  # ç©ºè¡Œåˆ†éš”

        # ç”Ÿæˆå¤„ç†æŠ¥å‘Š
        self.generate_processing_report(success_count, len(files))

    def generate_processing_report(self, success_count: int, total_count: int):
        """ç”Ÿæˆå¤„ç†æŠ¥å‘Š"""
        print("="*60)
        print("ğŸ“Š æ•°æ®å¤„ç†å®ŒæˆæŠ¥å‘Š")
        print("="*60)

        print(f"æ€»æ–‡ä»¶æ•°: {total_count}")
        print(f"æˆåŠŸå¤„ç†: {success_count}")
        print(f"å¤±è´¥æ•°é‡: {total_count - success_count}")
        print(f"æˆåŠŸç‡: {success_count/total_count*100:.1f}%")

        if self.processing_log:
            # æŒ‰å¹´ä»½æ’åº
            successful_files = [log for log in self.processing_log if log['status'] == 'success']
            successful_files.sort(key=lambda x: x['year'])

            print(f"\nğŸ“‹ æˆåŠŸå¤„ç†çš„æ–‡ä»¶:")
            for log in successful_files:
                print(f"  {log['year']}å¹´: {log['text_length']:,} å­—ç¬¦")

            # ä¿å­˜å¤„ç†æ—¥å¿—
            log_file = self.output_dir.parent / "processing_log.json"
            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump(self.processing_log, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ“„ å¤„ç†æ—¥å¿—å·²ä¿å­˜: {log_file}")

        print(f"\nğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
        print("âœ… æ•°æ®å¤„ç†å®Œæˆï¼")

    def check_output_files(self):
        """æ£€æŸ¥è¾“å‡ºæ–‡ä»¶"""
        print("ğŸ” æ£€æŸ¥è¾“å‡ºæ–‡ä»¶...")

        output_files = list(self.output_dir.glob("policy_address_*.txt"))
        output_files.sort()

        if not output_files:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•è¾“å‡ºæ–‡ä»¶")
            return

        print(f"ğŸ“ æ‰¾åˆ° {len(output_files)} ä¸ªè¾“å‡ºæ–‡ä»¶:")

        for file_path in output_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                # æå–å¹´ä»½
                year_match = re.search(r'policy_address_(\d{4})\.txt', file_path.name)
                year = year_match.group(1) if year_match else "æœªçŸ¥"

                print(f"  âœ… {year}å¹´: {len(content):,} å­—ç¬¦")

            except Exception as e:
                print(f"  âŒ {file_path.name}: è¯»å–å¤±è´¥ - {str(e)}")

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='é¦™æ¸¯æ–½æ”¿æŠ¥å‘Šæ•°æ®å¤„ç†å™¨')
    parser.add_argument('--source', default='data/pa', help='æºæ•°æ®ç›®å½•')
    parser.add_argument('--output', default='policy_data/raw_texts', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--check', action='store_true', help='æ£€æŸ¥è¾“å‡ºæ–‡ä»¶')

    args = parser.parse_args()

    processor = PolicyAddressProcessor(args.source, args.output)

    if args.check:
        processor.check_output_files()
    else:
        processor.process_all_files()

if __name__ == "__main__":
    main()
