# 香港施政报告知识图谱分析项目 - 完整交接文档

## 📋 项目概述

### 🎯 项目目标
基于1997-2024年香港特别行政区行政长官施政报告，构建知识图谱并进行多维度对比分析，研究香港政策话语的演变趋势。

### 📊 项目规模
- **时间跨度**: 1997-2024年（28年）
- **文档数量**: 26个施政报告（缺少2002年和2012年）
- **数据量**: 约70万字符的简体中文文本
- **分析维度**: 话语主题演变、实体网络结构、关系模式变化

## 🏗️ 项目架构

### 📁 目录结构

What_kgllm/ ├── data/pa/ # 原始PDF和XML文件 ├── policy_data/ # 处理后的数据 │ ├── raw_texts/ # 简体中文文本文件 (26个) │ ├── kg_json/ # 知识图谱JSON数据 (进行中) │ ├── kg_html/ # 可视化文件 │ ├── logs/ # 处理日志 │ └── metadata/ # 元数据信息 ├── src/ # 核心代码库 ├── config.toml # 配置文件 ├── data_processor.py # 数据预处理器 ├── policy_kg_batch_generator.py # 知识图谱生成器 ├── kg_generation_plan.py # 分阶段处理计划 ├── monitor_kg_progress.py # 进度监控器 └── policy_comparative_analyzer.py # 对比分析器
plain text
Apply

### 🔧 技术栈
- **语言**: Python 3.9+
- **LLM API**: 美团内部GPT-4 API
- **主要库**: pandas, numpy, matplotlib, seaborn, networkx, opencc
- **数据格式**: JSON, TXT, HTML

## 📈 项目进展状态

### ✅ 已完成阶段

#### 阶段0: 数据预处理 (100% 完成)
- ✅ 提取26个PDF/XML文件的文本内容
- ✅ 统一转换为简体中文格式
- ✅ 清理和标准化文本数据
- ✅ 生成处理日志和统计报告

**输出文件**: `policy_data/raw_texts/policy_address_YYYY.txt`

#### 阶段1: 知识图谱生成 (46% 完成)
- ✅ 已完成12个年份的知识图谱生成
- ✅ 总计150,416个三元组，24,137个实体
- 🔄 还有14个年份待处理

**已完成年份**: 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2013, 2014, 2024

**待完成年份**: 1997, 1998, 1999, 2000, 2001, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023

### 🔄 当前任务状态

**知识图谱生成分阶段计划**:

| 阶段 | 文件数 | 年份 | 状态 | 预计时间 |
|------|--------|------|------|----------|
| 阶段1 | 6个 | 2003-2019 (小文件) | 67% 完成 | 30-60分钟 |
| 阶段2 | 7个 | 2000-2010 (中等文件) | 86% 完成 | 60-90分钟 |
| 阶段3 | 7个 | 1997-2016 (大文件) | 43% 完成 | 90-120分钟 |
| 阶段4 | 6个 | 1998-2024 (超大文件) | 17% 完成 | 120-180分钟 |

## 🚀 后续操作指南

### 立即要做的任务

#### 1. 完成知识图谱生成 (优先级: 🔥 高)

**检查当前状态**:
```bash
cd /path/to/What_kgllm
python3 kg_generation_plan.py --plan

展开
继续处理剩余文件:
sh
Apply
# 继续所有剩余阶段
python3 kg_generation_plan.py --all

# 或分阶段执行
python3 kg_generation_plan.py --stage 1  # 完成阶段1
python3 kg_generation_plan.py --stage 3  # 处理阶段3
python3 kg_generation_plan.py --stage 4  # 处理阶段4

监控进度:
sh
Apply
# 启动进度监控 (建议在后台运行)
python3 monitor_kg_progress.py --interval 60 &

预计完成时间: 2-4小时（取决于API响应速度）
2. 处理异常文件 (优先级: 🔥 高)
问题: 2004年文件只有3个三元组，明显异常
解决方案:
sh
Apply
# 重新处理2004年文件
python3 policy_kg_batch_generator.py --generate --start-year 2004 --end-year 2004 --force

下一阶段任务
阶段2: 多维度对比分析 (优先级: 🔥 高)
等知识图谱生成完成后立即开始
主要分析内容:
话语主题演变分析
识别10个主要话语主题
分析各主题在不同年份的占比变化
识别话语转变的关键节点
实体网络结构分析
计算网络密度、聚类系数等指标
分析中心性实体的变化
识别实体关系的演变模式
关系模式变化分析
统计关系类型的多样性变化
分析关系强度的时序变化
识别新兴关系模式
执行命令:
sh
Apply
# 运行完整对比分析
python3 policy_comparative_analyzer.py --analyze

# 检查分析结果
ls -la policy_data/analysis/
ls -la policy_data/visualizations/

预期输出:
分析报告 (Markdown格式)
可视化图表 (PNG格式)
统计数据 (JSON格式)
阶段3: 深度专题分析 (优先级: 🟡 中)
专题方向:
"一国两制"话语演变
经济政策重点变迁
民生政策发展轨迹
国家安全话语兴起
大湾区政策演进
实施方法:
基于已生成的知识图谱数据
针对特定主题进行深度挖掘
结合历史背景进行解读
🛠️ 技术配置说明
API配置
toml
Apply
[llm]
model = "gpt-4-0613"
api_key = "1871093020435750927"
base_url = "https://aigc.sankuai.com/v1/openai/native/chat/completions"
max_tokens = 4096
temperature = 0.2

知识图谱生成配置
toml
Apply
[chunking]
chunk_size = 120  # 适合施政报告的块大小
overlap = 25      # 保证政策连贯性

[standardization]
enabled = true
use_llm_for_entities = true
focus_entities = [
    "行政长官", "特区政府", "中央政府", "立法会",
    "一国两制", "基本法", "国家安全",
    "经济发展", "民生改善", "大湾区", "创新科技"
]

展开
批量处理策略
批次大小: 5个文件
文件间延迟: 10秒
批次间延迟: 30秒
自动错误恢复: 启用
🔍 质量检查要点
数据质量检查
文件完整性: 确保26个年份都有对应的知识图谱文件
三元组数量: 正常文件应有数千到数万个三元组
实体合理性: 检查提取的实体是否符合政策文档特征
关系多样性: 确保关系类型丰富且有意义
异常处理
空文件或极小文件: 重新处理
API错误: 检查logs目录下的错误日志
内存不足: 调整chunk_size参数
网络超时: 增加重试机制
📊 预期成果
最终交付物
完整知识图谱数据集 (26个JSON文件)
多维度分析报告 (Markdown + 可视化图表)
话语演变时间线 (交互式可视化)
政策主题变迁图 (网络图 + 热力图)
技术文档和使用说明
学术价值
首个基于知识图谱的香港施政报告系统性分析
为政策话语分析提供新的技术范式
为"一国两制"实践研究提供数据支撑
🚨 注意事项
技术风险
API限制: 注意调用频率，避免被限流
内存使用: 大文件处理时监控内存使用情况
数据一致性: 确保所有文件使用相同的处理参数
时间管理
知识图谱生成: 预留4-6小时
对比分析: 预留2-3小时
结果验证: 预留1-2小时
备份策略
sh
Apply
# 定期备份重要数据
tar -czf backup_$(date +%Y%m%d).tar.gz policy_data/

📞 应急联系
常见问题解决
进程卡死: pkill -f policy_kg
磁盘空间不足: 清理临时文件
API配额用完: 等待重置或联系管理员
重要文件位置
配置文件: config.toml
主要脚本: policy_kg_batch_generator.py
数据目录: policy_data/
日志目录: policy_data/logs/
🔄 任务中断和恢复机制
✅ 可以安全中断
进程级中断：
可以随时使用 Ctrl+C 中断正在运行的进程
或者直接关闭终端窗口
文件级恢复：
每个年份的知识图谱是独立生成的
已完成的文件会保存在 policy_data/kg_json/ 目录
重新启动时会自动跳过已完成的文件
错误处理：
单个文件处理失败不会影响其他文件
错误信息会保存在 policy_data/logs/ 目录
🔄 如何中断和恢复
中断方法：
sh
Apply
# 方法1：在终端按 Ctrl+C
# 方法2：关闭终端窗口
# 方法3：杀死进程
pkill -f policy_kg_batch_generator

恢复方法：
sh
Apply
# 检查当前状态
python3 kg_generation_plan.py --plan

# 继续执行特定阶段
python3 kg_generation_plan.py --stage 1

# 或继续执行所有剩余阶段
python3 kg_generation_plan.py --all

❌ 中断影响分析
会丢失当前文件的进度：
如果在处理某个年份文件的中途中断：
当前文件会丢失 - 正在处理的年份文件不会保存
需要重新开始 - 该文件会从头开始重新处理
已完成文件不受影响 - 其他已保存的文件完全安全
最佳中断时机：
在两个文件之间的等待期间（10秒延迟）
在批次之间的等待期间（30秒延迟）
看到 "⏳ 等待 X 秒..." 的提示时
不理想的中断时机：
正在处理某个文件的中途
看到 "Processing chunk X/Y" 时
正在调用LLM API时
📋 当前具体进度状态
已完成的知识图谱文件 (12个)
年份
三元组数量
实体数量
关系类型
文件状态
2003
7,240
1,228
789
✅ 完成
2004
3
3
3
⚠️ 异常
2005
16,878
2,156
1,286
✅ 完成
2006
7,269
1,506
944
✅ 完成
2007
14,994
2,228
1,282
✅ 完成
2008
9,377
2,041
1,193
✅ 完成
2009
12,997
1,911
1,199
✅ 完成
2010
10,722
2,299
1,365
✅ 完成
2011
16,230
2,783
1,643
✅ 完成
2013
18,692
2,846
1,565
✅ 完成
2014
17,423
2,431
1,348
✅ 完成
2024
18,591
2,705
1,453
✅ 完成
总计: 150,416个三元组，24,137个实体
待完成的文件 (14个)
阶段1剩余 (小文件): 2017, 2018, 2019 阶段2剩余 (中等文件): 2000, 2001
阶段3剩余 (大文件): 1997, 1999, 2015, 2016 阶段4剩余 (超大文件): 1998, 2020, 2021, 2022, 2023
🎯 给接手AI Agent的建议
首先运行状态检查: python3 kg_generation_plan.py --plan
确认环境配置: 检查Python依赖和API配置
启动进度监控: 便于跟踪长时间运行的任务
分阶段执行: 不要一次性运行所有任务
及时备份: 重要节点及时保存数据
质量优先: 宁可慢一点也要确保数据质量
🚀 立即行动计划
第一步: 检查当前状态
sh
Apply
python3 kg_generation_plan.py --plan

第二步: 处理异常文件
sh
Apply
python3 policy_kg_batch_generator.py --generate --start-year 2004 --end-year 2004 --force

第三步: 继续剩余文件处理
sh
Apply
python3 kg_generation_plan.py --all

第四步: 启动进度监控
sh
Apply
python3 monitor_kg_progress.py --interval 60 &

第五步: 等待完成后开始分析
sh
Apply
python3 policy_comparative_analyzer.py --analyze

📊 项目当前状态总结
项目进度: 知识图谱生成阶段，已完成46% (12/26个文件)
数据质量: 良好，除2004年文件异常外其他文件正常
技术状态: 系统运行稳定，API配置正常
预计完成: 2-4小时内可完成全部知识图谱生成
下一步: 立即开始多维度对比分析
项目具有完整的中断恢复机制，可以随时安全中断和恢复。
祝项目顺利完成！🚀